{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание №9 по теме \"Языковое моделирование\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1ZzdKMYMEHLz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qVTP8ZHGELUs"
   },
   "outputs": [],
   "source": [
    "path_to_file = 'C:/Study/GO.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0PKZsuEELXB",
    "outputId": "d60fe3d8-101e-4b84-b18b-033d355e5e6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 394567 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxHVJ0fxELZG",
    "outputId": "7e69bf63-9bc8-4c1b-d467-0a204e327555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Автор: Егор Летов\r\n",
      "Альбом: Жизнь что сказка\r\n",
      "\r\n",
      "\r\n",
      "Заброшенное ж-д, заржавелый прогнивший завод,\r\n",
      "карликовый городок на горизонте,\r\n",
      "бродячие кучи деревьев, живых по привычке,\r\n",
      "разумеется, свалка, серые сумерки.\r\n",
      "Вот здесь-то меня и убили, а потом не нашли\n"
     ]
    }
   ],
   "source": [
    "print(text[5405:5660])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5SrzD336TLwG"
   },
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dm_78EWhELbm"
   },
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wgRcMLIFSpkH"
   },
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FuGyVuh7T1yj"
   },
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oA1mHtb8T10m"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kboom_e4T15N",
    "outputId": "e5e907de-c7f3-4635-82f7-d99be469901c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "W6Z6W2PpUFTv"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 128\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BAxV2PoDT17d"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "                                 \n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=False,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=False,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "         tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=False,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "                                   \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cAwPlaBOUWUK"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_Lt7XgGUWWs",
    "outputId": "e6dfc249-6ed6-40dc-dbc5-da4362f2172a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 146) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7zQMVJ9UxP_",
    "outputId": "51aa3198-7916-49ca-de24-2fb5d43ef481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         18688     \n",
      "                                                                 \n",
      " gru (GRU)                   (None, None, 1024)        3545088   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, None, 1024)        6297600   \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, None, 1024)        6297600   \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 146)         149650    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,308,626\n",
      "Trainable params: 16,308,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HuPB0b5qUxSg"
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LAFPSaY0UxVI"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nHmlY0RpV1aG"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = 'C:/Study/'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_freq=88*3,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9l37U8IcWMOX",
    "outputId": "b42464e9-0c04-4a83-8d91-eeb5bf87101b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "61/61 [==============================] - 383s 6s/step - loss: 3.2409\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 396s 6s/step - loss: 2.3633\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 394s 6s/step - loss: 2.0985\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 397s 7s/step - loss: 1.9391\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 399s 7s/step - loss: 1.7928\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 398s 7s/step - loss: 1.6484\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 401s 7s/step - loss: 1.5016\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 402s 7s/step - loss: 1.3635\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 405s 7s/step - loss: 1.2326\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 399s 7s/step - loss: 1.1084\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 398s 7s/step - loss: 0.9875\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 399s 7s/step - loss: 0.8676\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 402s 7s/step - loss: 0.7550\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 400s 7s/step - loss: 0.6425\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 402s 7s/step - loss: 0.5394\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 405s 7s/step - loss: 0.4471\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 402s 7s/step - loss: 0.3728\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 407s 7s/step - loss: 0.3138\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 401s 7s/step - loss: 0.2666\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 400s 7s/step - loss: 0.2331\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 401s 7s/step - loss: 0.2066\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 403s 7s/step - loss: 0.1867\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 404s 7s/step - loss: 0.1740\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 404s 7s/step - loss: 0.1641\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 402s 7s/step - loss: 0.1575\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 408s 7s/step - loss: 0.1495\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 402s 7s/step - loss: 0.1414\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 405s 7s/step - loss: 0.1346\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 404s 7s/step - loss: 0.1311\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 408s 7s/step - loss: 0.1293\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 411s 7s/step - loss: 0.1244\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 404s 7s/step - loss: 0.1215\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 404s 7s/step - loss: 0.1183\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 407s 7s/step - loss: 0.1155\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 410s 7s/step - loss: 0.1139\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 409s 7s/step - loss: 0.1130\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 407s 7s/step - loss: 0.1101\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 407s 7s/step - loss: 0.1094\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 409s 7s/step - loss: 0.1085\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 409s 7s/step - loss: 0.1079\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 407s 7s/step - loss: 0.1084\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 406s 7s/step - loss: 0.1072\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 412s 7s/step - loss: 0.1060\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 413s 7s/step - loss: 0.1067\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 409s 7s/step - loss: 0.1065\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 404s 7s/step - loss: 0.1072\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 407s 7s/step - loss: 0.1114\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 410s 7s/step - loss: 0.1141\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 410s 7s/step - loss: 0.1227\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 409s 7s/step - loss: 0.1436\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=50, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gVYB5_lGZAkK"
   },
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "hyREibcCZAm2",
    "outputId": "65e37720-c275-4fcf-e192-58a7b57c60cd"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "SWm8cuj7ZApQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 128)         18688     \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, None, 1024)        3545088   \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, None, 1024)        6297600   \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, None, 1024)        6297600   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 146)         149650    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,308,626\n",
      "Trainable params: 16,308,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ddQGqw3HZIbe"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  \n",
    "    num_generate = 500\n",
    "\n",
    "  \n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    temperature = 1\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "oZt6h_LJZArT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пелена невозможной ясности бессмертия —      ки Ле,    намобои-тыгамарнт A Вомежня     иры бисра)   выгаз.\r\n",
      "F#,  \r\n",
      "Я за ной епупрамы  C#,вся   уся,  кирушазазегамазама  ит  мия,D прте\r\n",
      "Am  A,ужамай  м ист\r\n",
      "Ле\r\n",
      "  Гам     ми\r\n",
      "Алиточи\r\n",
      "Онечля        стод  кулемо Лерий    нЕва Ленот\r\n",
      "Я   в, пои      ре.\r\n",
      "Ончемет коли кавортоз  ри      ой пу\r\n",
      "ЗИ виснь\r\n",
      "   сяс     мато\r\n",
      "\r\n",
      "В з  ироеборежамизо   G  A :   ра       —   азваразато ол\r\n",
      "И пи, мартах F#m   \r\n",
      "Летвобомый  ко   о\r\n",
      "Прасазуказм тыми\r\n",
      "Бо А   \r\n",
      "3 Димеса F            Em    раздетои, лто\r\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, start_string=u\"Пелена невозможной ясности бессмертия \")\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
